# Project Analysis Report (2025-07-26)

## Project Overview

### From README.md

# Literary Companion

Literary Companion is a web application designed to enrich the classic reading experience. As you read a novel, it provides a modern English translation and generates contextually relevant "fun facts" and trivia in a side panel, bringing the story's world to life.

Built with Python, Flask, and the Google Agent Development Kit (ADK), this project leverages the power of generative AI (Vertex AI) to create a dynamic and interactive companion for your literary journeys.

## Features

*   **Side-by-Side Reading:** View the original text alongside a modern, easy-to-understand English translation.
*   **On-Demand Fun Facts:** As you read, request "Fun Facts" related to the current passage. The application generates insights on:
    *   Historical Context
    *   Geographical Settings
    *   Plot Points
    *   Character Sentiments & Relationships
*   **Screenplay Generation Tools:** Includes tools to generate a high-level beat sheet or a detailed scene list from the novel text.
*   **Cloud-Native:** Utilizes Google Cloud Storage for book content and Vertex AI for generative tasks.

## Architecture Overview

The application operates using two primary workflows, both orchestrated by AI agents built with the Google ADK.

![Architecture Diagram](https://storage.googleapis.com/gcp-community/images/adk/lit-comp-arch.png)

### 1. Book Preparation (A One-Time Process)

Before a novel can be read in the UI, it must be prepared. This is a batch process that you run once for each book.

*   **How it works:** A script invokes the `BookPreparationCoordinator` agent. This agent uses a tool to read the novel's raw text from Google Cloud Storage (GCS), splits it into paragraphs, and uses a generative model to translate each paragraph into modern English. The final structured data (original text, translated text, paragraph IDs) is saved as a single JSON file back into GCS.

### 2. Fun Fact Generation (The Interactive Experience)

This is the core interactive loop that happens as a user reads the book.

*   **How it works:** The web interface tracks the user's reading progress. When the "Show Fun Facts" button is clicked, the text read so far is sent to the backend Flask API. The API invokes the `FunFactCoordinator` agent, which in turn uses an orchestrator tool to generate different types of fun facts in parallel. These facts are generated by a set of specialized functions that call Vertex AI. The results are collected and sent back to the user's browser.

### Key Technologies

*   **Backend:** Python with Flask
*   **AI Agent Framework:** Google Agent Development Kit (ADK)
*   **Generative AI:** Google Cloud Vertex AI
*   **Storage:** Google Cloud Storage (GCS)
*   **Task Coordination:** Google Cloud Firestore (used as a temporary "task board" for fun fact generation)
*   **Frontend:** Vanilla HTML, CSS, and JavaScript

## Getting Started

Follow these steps to get the Literary Companion running on your local machine.

### Prerequisites

*   Python 3.9+
*   A Google Cloud Project with billing enabled.
*   The `gcloud` CLI installed and authenticated.
*   APIs Enabled: Vertex AI, Cloud Storage, Firestore.

### Installation

1.  **Clone the repository:**
    ```bash
    git clone <your-repo-url>
    cd lit-comp
    ```

2.  **Set up a virtual environment:**
    ```bash
    python -m venv .venv
    source .venv/bin/activate
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configure Environment Variables:**
    Create a `.env` file in the project root and add the necessary configuration. This file is loaded by the Flask application for local development.

    ```env
    # .env

    # --- GCP Configuration ---
    GOOGLE_CLOUD_PROJECT="your-gcp-project-id"
    GOOGLE_CLOUD_LOCATION="your-gcp-region" # e.g., us-central1

    # --- Application Specific ---
    GCS_BUCKET_NAME="your-gcs-bucket-name"
    GCS_FILE_NAME="name-of-your-book.txt" # The book to load by default

    # --- AI Model Configuration ---
    DEFAULT_AGENT_MODEL="gemini-1.5-flash-001"
    GOOGLE_GENAI_USE_VERTEXAI=TRUE
    ```

### Usage

1.  **Upload a Book:** Upload a plain text (`.txt`) version of a novel to your GCS bucket.

2.  **Prepare the Book:** Run the book preparation script, pointing it to the file you just uploaded.
    ```bash
    python scripts/run_book_preparation.py --bucket "your-gcs-bucket-name" --file "name-of-your-book.txt"
    ```
    This will create a `_prepared.json` file in your bucket.

3.  **Run the Web Application:**
    Start the Flask development server.
    ```bash
    python app.py
    ```

4.  **Open in Browser:** Navigate to `http://127.0.0.1:5001` to start reading.

### Utility Scripts

#### Filtering a Prepared Book

After preparing a book, you may want to create a smaller version for testing or demos. The `scripts/filter_prepared_book.py` script allows you to do this.

-   **Purpose**: Creates a new `_prepared.json` file containing only chapters up to a specified number.
-   **Usage**:
    ```bash
    python scripts/filter_prepared_book.py path/to/your_book_prepared.json 10
    ```
    This command will create a new file (e.g., `your_book_prepared_chap_1-10.json`) in the same directory, containing only the content from chapters 1 through 10.

## How to Contribute

We welcome contributions! Here are a few ideas to get you started:

1.  **Immersive Audio Experience:**
    Add a "Listen" button that generates and plays short, relevant audio clips for the current scene. This could involve creating a new tool that uses a text-to-audio generation model to create background soundscapes (e.g., a bustling 19th-century London street, the creaking of a ship at sea) or sound effects for key actions.

2.  **Multi-Format Book Support:**
    Currently, the application only processes `.txt` files. A great enhancement would be to extend the `book_processor_tool` to handle popular ebook formats like `.epub` and `.pdf`. This would require adding libraries like `ebooklib` and `PyPDF2` to parse these files and extract their text content before passing it to the translation and analysis pipeline.

3.  **Persistent User Sessions with Redis:**
    The current `InMemorySessionService` loses user history when the app restarts, which is not ideal for a production environment. A valuable contribution would be to replace it with a persistent session store using Redis. This would involve creating a `RedisSessionService` class that implements the `BaseSessionService` interface, connecting to a Redis instance, and handling the serialization/deserialization of session data.

## License

This project is licensed under the Apache 2.0 License.

### From ARCHITECTURE.md

# Architecture Document: Literary Companion

## 1. Introduction

This document provides a comprehensive overview of the architecture of the Literary Companion application. It details the various components, their interactions, the deployment workflow, and the specific Google Cloud services utilized. The application is designed to assist users in preparing literary works and generating screenplays, leveraging large language models (LLMs) and cloud-native services.

## 2. Overall Architecture

The Literary Companion application follows a modular and cloud-native architecture, primarily deployed on Google Cloud Platform (GCP). It consists of a core Flask web application, background processing scripts, and a suite of specialized agents and tools that interact with various GCP services, particularly for LLM-driven tasks and data storage.

```
+-------------------+     +---------------------+     +---------------------+
|                   |     |                     |     |                     |
|   User Interface  |<--->|  Flask Web App      |<--->|  Literary Agents    |
|   (Browser)       |     |    (app.py)         |     |  (Book Prep, Screenplay) |
|                   |     |                     |     |                     |
+-------------------+     +---------------------+     +---------------------+
                                   |       ^
                                   |       |
                                   v       |
+---------------------+     +---------------------+     +---------------------+
|                     |     |                     |     |                     |
|  Background Scripts |<--->|  Specialized Tools  |<--->|  Google Cloud Services |
|  (run_book_prep,    |     |  (GCS, Screenplay,  |     |  (Vertex AI, GCS,    |
|   run_screenplay)   |     |   Translation)      |     |   Firestore, Cloud Run) |
|                     |     |                     |     |                     |
+---------------------+     +---------------------+     +---------------------+
```

## 3. Core Application (`app.py`)

`app.py` serves as the main entry point for the web application. It is a Flask-based application responsible for:

*   **Serving the User Interface**: Renders HTML templates (from the `templates/` directory) to provide the user-facing interface.
*   **API Endpoints**: Exposes RESTful API endpoints for initiating workflows (e.g., book preparation, screenplay creation) and retrieving results.
*   **Orchestration**: Interacts with the `literary_companion/agents/` to delegate complex, LLM-driven tasks.
*   **Configuration**: Utilizes settings defined in `literary_companion/config.py`.

## 4. Deployment Workflow

The application is containerized using Docker and deployed to Google Cloud Run, enabling a serverless, scalable, and cost-effective deployment model.

*   **Dockerfile**: Defines the build process for the Docker image. It uses a multi-stage build to create a lean final image, installing Python dependencies into a virtual environment and copying only the necessary application code.
*   **.dockerignore**: Specifies files and directories to exclude from the Docker build context, ensuring a smaller and more secure image.
*   **requirements.txt**: Lists all Python dependencies required by the application.
*   **gcenv.sh.example / gcenv.sh**: A shell script template for managing environment variables (e.g., `PROJECT_ID`, `LOCATION`, `IMAGE_NAME`, `SERVICE_NAME`) specific to different deployment environments. This script is sourced before deployment.
*   **deploy_cloud_run.sh**: An automated script that orchestrates the deployment to Cloud Run. It performs the following steps:
    1.  Verifies that necessary environment variables are set.
    2.  Prompts for user confirmation before proceeding.
    3.  Deploys the Docker image to Google Cloud Run, configuring service parameters such as image URL, platform, region, authentication, CPU, memory, and environment variables.
    4.  Outputs the Cloud Run service account name, which is crucial for subsequent IAM role assignments.
*   **Google Cloud Run**: The serverless platform where the application runs. It automatically scales the application up and down based on traffic, including scaling to zero instances when idle.
*   **Artifact Registry**: Google Cloud's universal package manager, used here to store the Docker images built for the application. The `deploy_cloud_run.sh` script pushes the built image to a designated Docker repository within Artifact Registry.

## 5. Book Preparation Workflow

This workflow processes raw book files, preparing them for further analysis or use within the application.

*   **Trigger**: Initiated via `scripts/run_book_preparation.py`, which can be run as a background job or manually.
*   **Agent**: `literary_companion/agents/book_preparation_coordinator_v1.py`. This agent is responsible for:
    *   Receiving a raw book file (e.g., from GCS).
    *   Orchestrating the parsing, cleaning, and structuring of the book content.
    *   Potentially interacting with LLMs for tasks like summarization or entity extraction.
    *   Storing the processed book data.
*   **Tools Used**:
    *   `literary_companion/tools/gcs_tool.py`: Used for reading raw book files from a Google Cloud Storage bucket and writing the processed book data back to GCS.
*   **Output**: Structured, processed book data stored in Google Cloud Storage, ready for subsequent workflows.

## 6. Screenplay Creation Workflow

This workflow generates a screenplay based on provided input, likely leveraging the processed book data.

*   **Trigger**: Initiated via `scripts/run_screenplay_creation.py`, which can be run as a background job or manually.
*   **Agent**: `literary_companion/agents/screenplay_coordinator_v1.py`. This agent is responsible for:
    *   Taking input (e.g., processed book data, user prompts).
    *   Coordinating the generation of a screenplay, likely involving multiple LLM calls for character development, scene descriptions, dialogue, etc.
    *   Structuring the generated screenplay into a desired format.
*   **Tools Used**:
    *   `literary_companion/tools/screenplay_generator_tool.py`: A specialized tool that encapsulates the logic for interacting with LLMs to generate screenplay elements.
    *   `literary_companion/tools/gcs_tool.py`: Used for reading input data (e.g., processed book) from GCS and writing the final generated screenplay to GCS.
*   **Output**: A complete screenplay document stored in Google Cloud Storage.

## 7. Key Components and Tools

Beyond the core workflows, several shared components and tools facilitate the application's functionality:

*   **`literary_companion/lib/fun_fact_generators.py`**: Contains logic for generating "fun facts," likely by querying LLMs with specific prompts based on input text.
*   **`literary_companion/tools/translation_tool.py`**: Provides functionality for translating text, leveraging LLMs or dedicated translation APIs.
*   **`literary_companion/tools/gcs_tool.py`**: A utility module for interacting with Google Cloud Storage. It provides functions for uploading and downloading blobs (files) to and from specified GCS buckets. This tool is fundamental for handling large input files (books) and storing processed outputs (prepared books, screenplays).
*   **`literary_companion/config.py`**: A centralized configuration file that stores application-wide settings, such as Google Cloud project IDs, bucket names, and LLM model names. This promotes maintainability and allows for easy adjustment of parameters across different environments.

## 8. Caching Mechanism

The application leverages Google Cloud Storage (GCS) as a persistent caching mechanism for the outputs of long-running and computationally expensive processes, specifically the book preparation and screenplay creation workflows.

*   **Mechanism**: Before initiating a book preparation or screenplay generation task, the system first checks if a pre-computed or pre-processed version of the output already exists in a designated GCS bucket. This check is typically based on a unique identifier derived from the input (e.g., a hash of the book content or a combination of input parameters for screenplay generation).
*   **How it Works**:
    1.  When a request for book preparation or screenplay generation comes in, the relevant agent (e.g., `BookPreparationCoordinatorV1`) computes a unique key for the expected output.
    2.  It then uses `gcs_tool.py` to check if a blob with this key exists in the designated GCS cache bucket.
    3.  If the blob exists, the agent downloads the cached output directly from GCS and returns it, bypassing the entire processing pipeline.
    4.  If the blob does not exist, the agent proceeds with the full computation (e.g., LLM calls, data processing).
    5.  Once the computation is complete, the agent uploads the newly generated output to the GCS cache bucket using the computed key, making it available for future requests.

*   **Advantages Compared to Not Using a Cache**:
    *   **Reduced Computation Cost**: The most significant advantage is avoiding redundant execution of expensive LLM calls and complex data processing. This directly translates to lower operational costs, especially for services like Vertex AI which are billed per token or per request.
    *   **Faster Response Times**: For repeated requests or common inputs, the system can serve results almost instantaneously from the cache, dramatically improving user experience by reducing latency from minutes (for full processing) to seconds (for cache retrieval).
    *   **Improved Scalability and Throughput**: By offloading repeated computations to the cache, the system can handle a higher volume of requests without needing to scale up its compute resources (e.g., Cloud Run instances, LLM quotas) proportionally. This reduces contention for LLM APIs.
    *   **Enhanced Resilience and Reliability**: Cached results provide a fallback. If the underlying LLM service experiences an outage or the processing pipeline encounters an error, previously computed results can still be served from the cache, maintaining partial service availability.
    *   **Reduced API Quota Consumption**: For LLM services with rate limits or quotas, caching helps stay within those limits by minimizing the number of actual API calls.

## 9. Google Cloud Services Utilized

The Literary Companion application heavily relies on the following Google Cloud services:

*   **Cloud Run**: The primary serverless compute platform for hosting the Flask web application. It provides automatic scaling, traffic management, and integrates seamlessly with other GCP services.
*   **Artifact Registry**: Used for secure and private storage of Docker container images.
*   **Vertex AI**: Google Cloud's machine learning platform, specifically utilized for accessing Large Language Models (LLMs). This service powers the generative capabilities for tasks like fun fact generation, translation, book summarization, and screenplay creation.
*   **Cloud Storage (GCS)**: A highly scalable and durable object storage service. It serves multiple purposes:
    *   **Raw Input Storage**: Stores the original book files uploaded by users.
    *   **Processed Data Storage**: Stores the intermediate and final outputs of workflows, such as prepared book data and generated screenplays.
    *   **Caching Layer**: Acts as the persistent cache for computationally expensive results, as detailed in Section 8.
*   **Firestore (in Datastore mode)**: A NoSQL document database used for storing application metadata, user data, or potentially tracking the status of long-running tasks. The `deploy_cloud_run.sh` script explicitly requests the `Cloud Datastore User` IAM role, indicating its usage.

## Repository Structure

### Entry Points

Potential entry points found:
- `./app.py`
- `./.venv/lib/python3.12/site-packages/dotenv/main.py`
- `./.venv/lib/python3.12/site-packages/flask/app.py`
- `./.venv/lib/python3.12/site-packages/pip/_internal/main.py`
- `./.venv/lib/python3.12/site-packages/pip/_internal/cli/main.py`
- `./.venv/lib/python3.12/site-packages/pydantic_settings/main.py`
- `./.venv/lib/python3.12/site-packages/pydantic/main.py`
- `./.venv/lib/python3.12/site-packages/pydantic/v1/main.py`
- `./.venv/lib/python3.12/site-packages/uvicorn/main.py`

### Resources and Services

The following Google Cloud services appear to be used:
- Compute Engine
- Google Cloud Storage
- Google Kubernetes Engine
- Cloud Functions
- Vertex AI
- Cloud Run
- BigQuery

## Commit History

### Commit Narrative

The project's development history, as told by the commit messages, is as follows:

- **2 months ago**: Initial commit of the CIE project cie-0 (by *Ed Sponsler*)
- **10 weeks ago**: Completed Building CIE Tutorial Part 0 20250518 (by *Ed Sponsler*)
- **9 weeks ago**: Part 1 Completed (by *Ed Sponsler*)
- **9 weeks ago**: Implemented core interaction bewteen Coordinator and first specialist agent. (by *Ed Sponsler*)
- **9 weeks ago**: Completed Core CIE requirements. (by *Ed Sponsler*)
- **9 weeks ago**: Completed real search tool and core agent pipeline (by *Ed Sponsler*)
- **9 weeks ago**: added example-output.txt showing a successful run of  run_coordinator_level_1_test.py. (by *Ed Sponsler*)
- **9 weeks ago**: Update .gitignore with new patterns (by *Ed Sponsler*)
- **9 weeks ago**: Remove files and folders now ignored by .gitignore (by *Ed Sponsler*)
- **9 weeks ago**: Deployed Web UI to Cloud Run (by *Ed Sponsler*)
- **9 weeks ago**: Add files via upload (by *Ed Sponsler*)
- **9 weeks ago**: Polished README.md for Core... (by *Ed Sponsler*)
- **9 weeks ago**: published README.md (by *Ed Sponsler*)
- **9 weeks ago**: polished formating in README.md (by *Ed Sponsler*)
- **9 weeks ago**: another formating correction in README.md and added alternative syntax in Dockerfile cmd (by *Ed Sponsler*)
- **9 weeks ago**: Create LICENSE Apache 2.0 (by *Ed Sponsler*)
- **8 weeks ago**: Update README.md (by *Ed Sponsler*)
- **8 weeks ago**: Update and rename run_coordinator_level_1_test.py to run_coordinator_test.py (by *Ed Sponsler*)
- **8 weeks ago**: Update and rename run_coordinator_test.py to run_cie_coordinator_test.py (by *Ed Sponsler*)
- **8 weeks ago**: Update app.py (by *Ed Sponsler*)
- **8 weeks ago**: Update README.md (by *Ed Sponsler*)
- **8 weeks ago**: Update README.md (by *Ed Sponsler*)
- **7 weeks ago**: refractored core to separate main from extension branches (by *Ed Sponsler*)
- **7 weeks ago**: Update README.md (by *Ed Sponsler*)
- **7 weeks ago**: fix(app): Specify explicit template folder path (by *Ed Sponsler*)
- **7 weeks ago**: Update README.md (by *Ed Sponsler*)
- **7 weeks ago**: Merge branch 'main' of github.com:edsponsler/cie-adk (by *Ed Sponsler*)
- **6 weeks ago**: Added Architectural Reference for the main branch (by *Ed Sponsler*)
- **6 weeks ago**: Rename ARCHITECTURE-main.md to ARCHITECTURE.md (by *Ed Sponsler*)
- **6 weeks ago**: feat(literary-companion): add book preparation workflow and fun fact backend (by *Ed Sponsler*)
- **6 weeks ago**: feat(literary-companion): implement frontend and complete end-to-end functionality (by *Ed Sponsler*)
- **6 weeks ago**: Added ARCHITECTURE.md for the feature/literary_compaion branch (by *Ed Sponsler*)
- **6 weeks ago**: chore(deploy): use Secret Manager for API keys in Cloud Run script (by *Ed Sponsler*)
- **5 weeks ago**: fix(docker): Align gunicorn worker with WSGI Flask app (by *Ed Sponsler*)
- **5 weeks ago**: fix: Resolve 500 error in fun facts generation API (by *Ed Sponsler*)
- **5 weeks ago**: Renamed README.md to TUTORIAL.md (by *Ed Sponsler*)
- **5 weeks ago**: Create README.md (by *Ed Sponsler*)
- **5 weeks ago**: Update ARCHITECTURE.md (by *Ed Sponsler*)
- **5 weeks ago**: Deleted redundant files README.md and ARCHITECTURE.md (by *Ed Sponsler*)
- **5 weeks ago**: Create README.md (by *Ed Sponsler*)
- **5 weeks ago**: fix(prepare-script): resolve client initialization error (by *Ed Sponsler*)
- **13 days ago**: feat(literary-companion): Add book reading and fun fact generation module (by *Ed Sponsler*)
- **13 days ago**: refactor(app): Remove cie_core and focus on literary_companion (by *Ed Sponsler*)
- **13 days ago**: fix(sdk): Address deprecation warnings in Cloud libraries (by *Ed Sponsler*)
- **13 days ago**: Merge branch 'feature/literary-companion' (by *Ed Sponsler*)
- **13 days ago**: feat(deploy): Standardize deployment and configuration (by *Ed Sponsler*)
- **13 days ago**: feat: Add standard README.md (by *google-labs-jules[bot]*)
- **13 days ago**: Merge pull request #1 from edsponsler/feat/add-readme (by *Ed Sponsler*)
- **13 days ago**: deleted TUTORIAL.md (by *Ed Sponsler*)
- **12 days ago**: feat(screenplay): Add screenplay generation workflow (by *Ed Sponsler*)
- **9 days ago**: refactor(config): Replace tracked gcenv.sh with untracked example (by *Ed Sponsler*)
- **7 days ago**: added a couple NEXT.md files (by *Ed Sponsler*)
- **6 days ago**: feat: Enable fun facts button and improve error handling (by *Ed Sponsler*)
- **6 days ago**: feat: Add chapter numbering and fun fact caching (by *Ed Sponsler*)
- **6 days ago**: updated README.md (by *Ed Sponsler*)
- **6 days ago**: updated README.md (by *Ed Sponsler*)
- **6 days ago**: feat: Optimize fun fact caching to avoid large file reads (by *Ed Sponsler*)
- **5 days ago**: refactor(fun-facts): Replace custom orchestrator with ADK-native agent (by *Ed Sponsler*)
- **4 days ago**: feat(fun-facts): Refactor to use full chapter context and add caching (by *Ed Sponsler*)
- **4 days ago**: refactor(fun-facts): Decouple context generation and use translated text (by *Ed Sponsler*)
- **4 days ago**: feat(ux, perf): Implement infinite scroll and multi-layer caching (by *Ed Sponsler*)
- **3 days ago**: feat(build, docs): Improve Docker build with multi-stage and update docs (by *Ed Sponsler*)
- **3 days ago**: adding example projalyzer file (by *Ed Sponsler*)
- **84 minutes ago**: feat(screenplay): Add enhanced screenplay generation agent (by *Ed Sponsler*)
- **50 minutes ago**: refactor(screenplay): Generate separate screenplay files per chapter (by *Ed Sponsler*)
